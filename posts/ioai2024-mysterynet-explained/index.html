<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>IOAI 2024 MysteryNet Explained | Tan Nian Wei</title><meta name=keywords content><meta name=description content="Hid something in these safetensors!"><meta name=author content><link rel=canonical href=https://tnwei.github.io/posts/ioai2024-mysterynet-explained/><link crossorigin=anonymous href=/assets/css/stylesheet.min.3f18978ad811c7ac935d52e17228171d2a4141b9d8c9c35a5899222d655e34b8.css integrity="sha256-PxiXitgRx6yTXVLhcigXHSpBQbnYycNaWJkiLWVeNLg=" rel="preload stylesheet" as=style><link rel=icon href=https://tnwei.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://tnwei.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://tnwei.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://tnwei.github.io/apple-touch-icon.png><link rel=mask-icon href=https://tnwei.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.119.0"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-TCJ4MGEGS8"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-TCJ4MGEGS8")</script><style>figcaption{text-align:center}</style><meta property="og:title" content="IOAI 2024 MysteryNet Explained"><meta property="og:description" content="Hid something in these safetensors!"><meta property="og:type" content="article"><meta property="og:url" content="https://tnwei.github.io/posts/ioai2024-mysterynet-explained/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-01T17:04:00+08:00"><meta property="article:modified_time" content="2024-09-01T17:04:00+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="IOAI 2024 MysteryNet Explained"><meta name=twitter:description content="Hid something in these safetensors!"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tnwei.github.io/posts/"},{"@type":"ListItem","position":2,"name":"IOAI 2024 MysteryNet Explained","item":"https://tnwei.github.io/posts/ioai2024-mysterynet-explained/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"IOAI 2024 MysteryNet Explained","name":"IOAI 2024 MysteryNet Explained","description":"Hid something in these safetensors!","keywords":[],"articleBody":" Selamat Hari Merdeka! :) At the end of IOAI 2024, I sent a gift to all students that required some elbow grease to open.\nAll the students are given is a safetensors file by their country / team name, and also this network definition below for a particular MysteryNet:\nclass MysteryNet(nn.Module): def __init__(self): super().__init__() self.dense1 = nn.Linear(in_features=2, out_features=16) self.dense2 = nn.Linear(in_features=16, out_features=32) self.bn2 = nn.BatchNorm1d(32) self.dense3 = nn.Linear(in_features=32, out_features=32) self.dense4 = nn.Linear(in_features=32, out_features=32) self.bn4 = nn.BatchNorm1d(32) self.dense5 = nn.Linear(in_features=32, out_features=32) self.dense6 = nn.Linear(in_features=32, out_features=32) self.bn6 = nn.BatchNorm1d(32) self.dense7 = nn.Linear(in_features=32, out_features=32) self.dense8 = nn.Linear(in_features=32, out_features=16) self.bn8 = nn.BatchNorm1d(16) self.dense_head = nn.Linear(in_features=16, out_features=3) def forward(self, x): x = self.dense1(x) x = F.gelu(x) x = self.dense2(x) x = F.gelu(x) x = self.bn2(x) x = self.dense3(x) x = F.gelu(x) x = self.dense4(x) x = F.gelu(x) x = self.bn4(x) x = self.dense5(x) x = F.gelu(x) x = self.dense6(x) x = F.gelu(x) x = self.bn6(x) x = self.dense7(x) x = F.gelu(x) x = self.dense8(x) x = F.gelu(x) x = self.bn8(x) x = self.dense_head(x) return x Here’s the link to the weights and mysterynet.py if you want to try it out yourself.\nExplanation MysteryNet has 2d inputs and 3d outputs. The dimension of the output itself is a hint that the output is in RGB space, but without any spatial priors owing to how the network architecture itself does not inherit any from the 2d inputs. With some trial and error, you might stumble upon using xy coordinates as the network input.\nWhat I did is to over-fit the networks to the point of being a hashmap that takes in image coordinates and outputs RGB values. This concept is called a compositional pattern-producing network (CPPN), introduced by Ken Stanley in 2007. I have misappropriated the idea to perform a belabored, lossy compression of your respective flags ;)\nThis exercise was inspired by this blogpost by David Ha, dating back to 2016.\nHere is a jumbo collage of what you should see if you formatted your input correctly:\nPardon the rough edges, I was in a rush\nMiscellanea The looping video at the top of the page is the training progression of the CPPN encoding the Malaysian flag. Apologies in advance if I wasn’t able to replicate your nation’s flag faithfully! All flags are found online and resized to have 320px width. Through this exercise I learnt that (1) there isn’t a standardized width-to-height ratio for flags, and (2) some nations have flags that are taller than they are wide! Easiest flags: Japan, Bangladesh, Poland Hardest flags: Iran, USA Most challenging bit was figuring out the training recipe in time before the conclusion of the event. The CPPNs were having difficulty reproducing details in some of the more elaborate flags. Probably not helped by my insistence on using the smallest feasible architecture. I eventually learnt to simply leave the networks to train. Turns out my chosen network architecture did have sufficient capacity to encode the flags, it was instead I who did not have enough patience. I was killing off training runs too early when I saw the losses plateau, but then I realized that it takes an exponential amount of time for the networks to get really small details right. Reminds me of this nugget of wisdom by Karpathy: leave it training. I’ve often seen people tempted to stop the model training when the validation loss seems to be leveling off. In my experience networks keep training for unintuitively long time. One time I accidentally left a model training during the winter break and when I got back in January it was SOTA (“state of the art”).\nThe final training recipe is a three stage affair: (1) train the network on a Gaussian blurred flag with some random noise added, (2) train the network to reproduce the original flag with random noise added (but less), then finally (3) leave the network to finetune on the flag with no noise added. The learning rate is decreased linearly across the duration of training. The idea is to get the general shapes and colours right, before allowing the network to work on the fine-grained details of the image. In my mind, blurring helped avoid sharp boundaries develop in easier parts of the image way ahead of the rest of the image, while random noise helped the network to avoid local minima that are easier to get in but hard to exit when finetuning. Can’t verify these hunches though, didn’t have time to experiment. Thoughts on why the fine details are challenging and hypotheses on how to make training faster: the dense nature of the network means that changing the output for a single coordinate affects the outputs of its neighboring coordinates. My (unvalidated) conjecture is introducing some form of sparsity such that the network behaves like an ensemble of subnets that do not interact with each other might help. Why safetensors: don’t unpack pickle files from sources that you don’t trust! Pytorch save uses pickle under the hood, which is vulnerable to arbitrary code execution. In hindsight, including some positional encoding might help the CPPNs train a lot better. But it would also make the network less mysterious, which would be less exciting. Acknowledgements The idea to do this arose from speaking to Chris (Romania) over making interesting olympiad questions. Thanks to Fredrik’s (Sweden) interest in flags, I had someone to share my progress with as I was making this, which is greatly appreciated! Thanks to my students for being my beta-testers ;) ","wordCount":"914","inLanguage":"en","datePublished":"2024-09-01T17:04:00+08:00","dateModified":"2024-09-01T17:04:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://tnwei.github.io/posts/ioai2024-mysterynet-explained/"},"publisher":{"@type":"Organization","name":"Tan Nian Wei","logo":{"@type":"ImageObject","url":"https://tnwei.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://tnwei.github.io/ accesskey=h title="Tan Nian Wei (Alt + H)">Tan Nian Wei</a>
<span class=logo-switches></span></div><ul id=menu><li><a href=https://tnwei.github.io/writing/ title=Writing><span>Writing</span></a></li><li><a href="https://drive.google.com/file/d/1kWKGkamiCd7RZLssEBy3b-FT3r0jpwha/view?usp=sharing" title=Resume><span>Resume</span></a></li><li><a href=https://tnwei.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>IOAI 2024 MysteryNet Explained</h1><div class=post-meta><span title='2024-09-01 17:04:00 +0800 +0800'>Sep 1, 2024 Sun</span>&nbsp;·&nbsp;5 min</div></header><div class=post-content><div style=text-align:center><video width=600 autoplay muted loop style=display:block;margin:auto>
<source src=/images/msian-flag-progression.mp4 type=video/mp4></video><p><small><em>Selamat Hari Merdeka! :)</em></small></p></div><p>At the end of IOAI 2024, I sent a gift to all students that required some elbow grease to open.</p><figure><img loading=lazy src=/images/msian-gift-announcement-screenshot.jpeg alt="Screenshot of the gift announcement in Discord"></figure><p>All the students are given is a <code>safetensors</code> file by their country / team name, and also this network definition below for a particular <code>MysteryNet</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>MysteryNet</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dense1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, out_features<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dense2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>, out_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>bn2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BatchNorm1d(<span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dense3 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, out_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dense4 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, out_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>bn4 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BatchNorm1d(<span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dense5 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, out_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dense6 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, out_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>bn6 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BatchNorm1d(<span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dense7 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, out_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dense8 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, out_features<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>bn8 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BatchNorm1d(<span style=color:#ae81ff>16</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dense_head <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>, out_features<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dense1(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>gelu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dense2(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>gelu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>bn2(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dense3(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>gelu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dense4(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>gelu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>bn4(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dense5(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>gelu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dense6(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>gelu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>bn6(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dense7(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>gelu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dense8(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>gelu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>bn8(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dense_head(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span></code></pre></div><p>Here&rsquo;s <a href=https://drive.google.com/drive/u/1/folders/1HbonYHOuCLRBPWQcC-ZaXQVBT_ry_nSX>the link</a> to the weights and <code>mysterynet.py</code> if you want to try it out yourself.</p><h1 id=explanation>Explanation<a hidden class=anchor aria-hidden=true href=#explanation>#</a></h1><p><code>MysteryNet</code> has 2d inputs and 3d outputs. The dimension of the output itself is a hint that the output is in RGB space, but without any spatial priors owing to how the network architecture itself does not inherit any from the 2d inputs. With some trial and error, you might stumble upon using xy coordinates as the network input.</p><p>What I did is to over-fit the networks to the point of being a hashmap that takes in image coordinates and outputs RGB values. This concept is called a compositional pattern-producing network (CPPN), introduced by Ken Stanley in 2007. I have misappropriated the idea to perform a belabored, lossy compression of your respective flags ;)</p><p>This exercise was inspired by <a href=https://blog.otoro.net/2016/03/25/generating-abstract-patterns-with-tensorflow/>this blogpost</a> by David Ha, dating back to 2016.</p><p>Here is a jumbo collage of what you should see if you formatted your input correctly:</p><figure class=align-center><img loading=lazy src=/images/ioai2024-msian-gift-collage.jpeg#center alt="Collage of various flags hidden in CPPN weights!"><figcaption><p>Pardon the rough edges, I was in a rush</p></figcaption></figure><h1 id=miscellanea>Miscellanea<a hidden class=anchor aria-hidden=true href=#miscellanea>#</a></h1><ul><li>The looping video at the top of the page is the training progression of the CPPN encoding the Malaysian flag.</li><li>Apologies in advance if I wasn&rsquo;t able to replicate your nation&rsquo;s flag faithfully!</li><li>All flags are found online and resized to have 320px width. Through this exercise I learnt that (1) there isn&rsquo;t a standardized width-to-height ratio for flags, and (2) some nations have flags that are taller than they are wide!</li><li>Easiest flags: Japan, Bangladesh, Poland</li><li>Hardest flags: Iran, USA</li><li>Most challenging bit was figuring out the training recipe in time before the conclusion of the event. The CPPNs were having difficulty reproducing details in some of the more elaborate flags. Probably not helped by my insistence on using the smallest feasible architecture.</li><li>I eventually learnt to simply leave the networks to train. Turns out my chosen network architecture did have sufficient capacity to encode the flags, it was instead I who did not have enough patience. I was killing off training runs too early when I saw the losses plateau, but then I realized that it takes an exponential amount of time for the networks to get really small details right. Reminds me of this nugget of wisdom <a href=http://karpathy.github.io/2019/04/25/recipe/>by Karpathy</a>:</li></ul><blockquote><p><em>leave it training. I’ve often seen people tempted to stop the model training when the validation loss seems to be leveling off. In my experience networks keep training for unintuitively long time. One time I accidentally left a model training during the winter break and when I got back in January it was SOTA (“state of the art”)</em>.</p></blockquote><ul><li>The final training recipe is a three stage affair: (1) train the network on a Gaussian blurred flag with some random noise added, (2) train the network to reproduce the original flag with random noise added (but less), then finally (3) leave the network to finetune on the flag with no noise added. The learning rate is decreased linearly across the duration of training. The idea is to get the general shapes and colours right, before allowing the network to work on the fine-grained details of the image. In my mind, blurring helped avoid sharp boundaries develop in easier parts of the image way ahead of the rest of the image, while random noise helped the network to avoid local minima that are easier to get in but hard to exit when finetuning. Can&rsquo;t verify these hunches though, didn&rsquo;t have time to experiment.</li><li>Thoughts on why the fine details are challenging and hypotheses on how to make training faster: the dense nature of the network means that changing the output for a single coordinate affects the outputs of its neighboring coordinates. My (unvalidated) conjecture is introducing some form of sparsity such that the network behaves like an ensemble of subnets that do not interact with each other might help.</li><li>Why safetensors: don&rsquo;t unpack pickle files from sources that you don&rsquo;t trust! Pytorch save uses pickle under the hood, which is vulnerable to arbitrary code execution.</li><li>In hindsight, including some positional encoding might help the CPPNs train a lot better. But it would also make the network less mysterious, which would be less exciting.</li></ul><h1 id=acknowledgements>Acknowledgements<a hidden class=anchor aria-hidden=true href=#acknowledgements>#</a></h1><ul><li>The idea to do this arose from speaking to Chris (Romania) over making interesting olympiad questions.</li><li>Thanks to Fredrik&rsquo;s (Sweden) interest in flags, I had someone to share my progress with as I was making this, which is greatly appreciated!</li><li>Thanks to my students for being my beta-testers ;)</li></ul></div><footer class=post-footer></footer><script src=https://giscus.app/client.js data-repo=tnwei/tnwei.github.io data-repo-id=R_kgDOGmOfvQ data-category=Announcements data-category-id=DIC_kwDOGmOfvc4CAeit data-mapping=og:title data-reactions-enabled=0 data-emit-metadata=0 data-theme=light data-lang=en crossorigin=anonymous async></script><noscript></noscript></article></main><footer class=footer><span>&copy; 2025 <a href=https://tnwei.github.io/>Tan Nian Wei</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>