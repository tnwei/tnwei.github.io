<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>MLflow x Hydra | Tan Nian Wei</title>
<meta name=keywords content="mlops">
<meta name=description content="A template for using both effectively in machine learning experiments">
<meta name=author content>
<link rel=canonical href=https://tnwei.github.io/posts/mlflow-x-hydra/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.3f18978ad811c7ac935d52e17228171d2a4141b9d8c9c35a5899222d655e34b8.css integrity="sha256-PxiXitgRx6yTXVLhcigXHSpBQbnYycNaWJkiLWVeNLg=" rel="preload stylesheet" as=style>
<link rel=icon href=https://tnwei.github.io/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://tnwei.github.io/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://tnwei.github.io/favicon-32x32.png>
<link rel=apple-touch-icon href=https://tnwei.github.io/apple-touch-icon.png>
<link rel=mask-icon href=https://tnwei.github.io/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.91.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-TCJ4MGEGS8"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-TCJ4MGEGS8')</script>
<style>figcaption{text-align:center}</style>
<meta property="og:title" content="MLflow x Hydra">
<meta property="og:description" content="A template for using both effectively in machine learning experiments">
<meta property="og:type" content="article">
<meta property="og:url" content="https://tnwei.github.io/posts/mlflow-x-hydra/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-06-13T20:58:18+08:00">
<meta property="article:modified_time" content="2022-06-13T20:58:18+08:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="MLflow x Hydra">
<meta name=twitter:description content="A template for using both effectively in machine learning experiments">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tnwei.github.io/posts/"},{"@type":"ListItem","position":2,"name":"MLflow x Hydra","item":"https://tnwei.github.io/posts/mlflow-x-hydra/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"MLflow x Hydra","name":"MLflow x Hydra","description":"A template for using both effectively in machine learning experiments","keywords":["mlops"],"articleBody":"A template for using both effectively in machine learning experiments I like using MLflow for experiment tracking, and Hydra for experiment configuration management and hyperparameter tuning. MLflow enables logging and visualizing all relevant info for each machine learning model trained without much effort. Hydra drastically simplifies managing and running experiments involving lots of hyperparameters, without requiring much extra code.\nAlthough both libraries are functionally complementary, there are subtle interactions between them that can lead to unexpected gotchas that are barely mentioned on the internet. After a couple of projects, I eventually arrived at the annotated script template below for using MLflow and Hydra effectively in the same codebase.\nIf you’re looking for a tweaked and tested template integrating both libraries to kick start your work, you might find this post useful.\nTraining script template The sample config and training script template can be found at tnwei/mlflow-x-hydra, reproduced below for copy-paste convenience.\nconf/train.yaml # Metadata # -------- expname: testrun runname: # Left blank on purpose, to be specified in CLI # Hyperparameters # --------------- n_epochs: 10 lr: 1e-5 batch_size: 32 # Hydra-specific config # --------------------- # The following stores single runs and multiruns (sweeps) in a hidden .hydra dir hydra: run: ¦ dir: .hydra/${now:%Y-%m-%d_%H-%M-%S} ¦ # If this works for you why not ¦ # dir: .hydra/${expname}/${now:%Y-%m-%d_%H-%M-%S} sweep: ¦ dir: .hydra/${now:%Y-%m-%d_%H-%M-%S} ¦ # If this works for you why not ¦ # dir: .hydra/${expname}/${now:%Y-%m-%d_%H-%M-%S} ¦ subdir: ${hydra.job.num} main.py \"\"\" Example multirun command: python main.py -m runname=testrun lr=1e-4,5e-5,1e-5,5e-6 \"\"\" # Import everything we need # ------------------------- import sys from pathlib import Path import random import matplotlib.pyplot as plt # Import hydra and mlflow # ----------------------- import hydra import mlflow # Obtain current working directory outside Hydra # ---------------------------------------------- # Why: wd is changed temporarily for each Hydra run # Original wd can still be retrieved at runtime with # hydra.utils.get_original_cwd() # But I prefer sticking to std lib when possible wd = Path(__file__).parent.resolve() # Define MLflow tracking and artifact storage URI # ----------------------------------------------- # This is required whenever a new MLflow experiment is defined # Do not change halfway through! Stick to one # Migrating mlflow backend is non-trivial # Default config: local backend + local artifact store # Command for UI: mlflow ui # Format for folder is `file://` + absolute file path, following file URI scheme TRACKING_URI = f\"file://{wd}/mlruns\" # This is default location ARTIFACT_URI = TRACKING_URI # Alternative config: sqlite backend + local artifact store # Command for UI: mlflow ui --backend-store-uri sqlite:///mlruns.sqlite # Format for sqlite is `sqlite:///` + absolute file path. Three slashes! # TRACKING_URI = f\"sqlite:///{wd}/mlruns.sqlite\" # ARTIFACT_URI = f\"file://{wd}/mlruns\" # More options available but omitted for brevity # See https://www.mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded mlflow.set_tracking_uri(TRACKING_URI) # Main logic # ---------- # Main training logic needs to be: # (1) packaged into a function # (2) wrapped with hydra.main() decorator # (3) and called at the end of the script # for Hydra to work # # Config path is dir to where the config is stored # Config name is the name of the config file @hydra.main(config_path=\"conf\", config_name=\"train.yaml\") def main(cfg): # Hydra config parsing # -------------------- # cfg is literally a dict of everything defined in the conf file # or passed from CLI # refer to conf.yaml for example print(cfg) # Unpack variables that will be used multiple times throughout the script # ----------------------------------------------------------------------- # Why: This is to keep the script modular if migrating away from Hydra # Saves time if want to switch to some other runner e.g. Weights and Biases sweeps n_epochs = cfg.n_epochs lr = cfg.lr batch_size = cfg.batch_size # Set MLFlow experiment # --------------------- # All runs recorded under the same exp name will show up on the same table in MLFlow # Create exp if not exists if mlflow.get_experiment_by_name(cfg.expname) is None: mlflow.create_experiment( name=cfg.expname, artifact_location=ARTIFACT_URI + \"/\" + cfg.expname ) mlflow.set_experiment(cfg.expname) # Explicitly set new MLFlow run # ----------------------------- # Explicitly set a new run: # Why 1: Running w/ hydra will pick up from a prev run # See https://stackoverflow.com/a/72605175/13095028 # Why 2: Allows fine-grained control over Run object e.g. setting `run_name` # Note: Leaving run_id to be auto-generated, since the randomly generated UUID is convenient activerun = mlflow.start_run(run_name=cfg.runname) # Explicitly configure savedir # ---------------------------- # Why: Create consistent savedir for all MLflow exps instead of using Hydra # Format: outputs/expname/runid/ # Hydra's approach will have one savedir for each run # Use run ID instead of run name as latter isn't always defined savedir = wd / \"outputs\" / f\"{cfg.expname}/{activerun.info.run_id}\" if not savedir.exists(): savedir.mkdir(parents=True) # Log hyperparameters # ------------------- # Params can only be logged once, while metrics are logged over time # Log dict of parameters mlflow.log_params(cfg) # Log one parameter # Note: found logging the command that triggered the file to run to be useful mlflow.log_param(\"argv\", \" \".join(sys.argv)) # Data loading and preprocessing # ------------------------------ # ... # YOUR CODE HERE # ... # Main training loop # ------------------ for epoch in range(n_epochs): # Model training # -------------- # ... # YOUR CODE HERE # ... # Compute evaluation metrics # -------------------------- print(f\"Calculating metrics at step {epoch}/{n_epochs}\") eval_metrics = {\"acc\": epoch / n_epochs} # Log metrics # ----------- # Log dict of metrics mlflow.log_metrics(eval_metrics, step=epoch) # Log one metric mlflow.log_metric(\"luck\", random.random(), step=epoch) # Save training outputs # --------------------- # Store artifacts by step in the defined savedir (savedir / f\"{i:02d}.csv\").touch() # Create a plot fig, ax = plt.subplots() ax.plot([0, 1], [2, 3]) # If needed, log training outputs to MLflow artifact store # -------------------------------------------------------- # Log one file mlflow.log_artifact(local_path=savedir / f\"{i:02d}.csv\") # Log the whole dir mlflow.log_artifacts(local_dir=savedir) # Log a figure mlflow.log_figure(fig, artifact_file=f\"{i:02d}.png\") # End MLflow run # -------------- # Alternative: wrap code in `with mlflow.start_run() as run:` mlflow.end_run() if __name__ == \"__main__\": main() Reasoning Elaborating upon the more opinionated parts of the template below:\nObtain current working directory outside Hydra # main.py wd = Path(__file__).parent.resolve() Hydra changes the work directory temporarily every time the script is executed. The idea is each script execution will have its outputs saved to a standalone folder. To refer to files based on the original working directory, we can either call hydra.utils.get_original_cwd(), or as I prefer it, save the original working directory using pathlib which is a standard library in Python.\nUnpack variables that will be used multiple times throughout the script # main.py n_epochs = cfg.n_epochs lr = cfg.lr batch_size = cfg.batch_size All specified configs will be made available through the cfg argument passed to the main() function, as items in a dictionary. Instead of directly referring to these values, I assign them to independent variables at the start of the script. I prefer keeping the Hydra-specific code localized to just the head of the script. In the event that I want to use another script runner like Weights and Biases sweeps instead, refactoring will just need tweaking a few lines.\nExplicitly set new MLFlow run # main.py activerun = mlflow.start_run(run_name=cfg.runname) An MLflow Run is created explicitly in the script template. The reasons are two-fold:\n If left to be automatically managed by MLflow, Hydra will consider all MLflow runs in the same Hydra multirun session to be the same. See my answer to this Stackoverflow question Explicit run creation allows greater control over the MLflow Run object. Example here is it allows us to set the run_name, which would be blank in the MLflow UI otherwise.  Explicitly configure savedir Out of the box, Hydra creates an outputs/directory to store the results of each execution, sorted by date. Results for each execution is saved in its own folder, using the current timestamp to the second as the folder name. Multiruns are stored in a separate multirun folder. This behaviour is convenient for integrating Hydra within existing code without much modification, but can be a bit tedious when it comes to accessing past results for future use.\n# main.py savedir = wd / \"outputs\" / f\"{cfg.expname}/{activerun.info.run_id}\" if not savedir.exists(): savedir.mkdir(parents=True) # conf/train.yaml hydra: run: dir: .hydra/${now:%Y-%m-%d_%H-%M-%S} sweep: dir: .hydra/${now:%Y-%m-%d_%H-%M-%S} subdir: ${hydra.job.num} In this script template, the output directory is explicitly configured to be  /outputs/, further sorted by experiment name and MLflow run ID. This approach consolidates all output into a single folder, compared to Hydra’s default approach. Given that Hydra still creates output directories for each execution, the template redirects them to a .hydra directory which is out of sight.\nI would have preferred using Hydra’s configuration to determine the save location instead of setting it aside completely, but the save locations are determined upon execution, and Hydra does not accept variables created at runtime. Using the Hydra config would rule out using auto-generated names, requiring the user to manually provide a name for each script execution.\n","wordCount":"1444","inLanguage":"en","datePublished":"2022-06-13T20:58:18+08:00","dateModified":"2022-06-13T20:58:18+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://tnwei.github.io/posts/mlflow-x-hydra/"},"publisher":{"@type":"Organization","name":"Tan Nian Wei","logo":{"@type":"ImageObject","url":"https://tnwei.github.io/favicon.ico"}}}</script>
</head>
<body id=top>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://tnwei.github.io/ accesskey=h title="Tan Nian Wei (Alt + H)">Tan Nian Wei</a>
<span class=logo-switches>
</span>
</div>
<ul id=menu>
<li>
<a href=https://tnwei.github.io/writing/ title=Writing>
<span>Writing</span>
</a>
</li>
<li>
<a href="https://drive.google.com/file/d/1kWKGkamiCd7RZLssEBy3b-FT3r0jpwha/view?usp=sharing" title=Resume>
<span>Resume</span>
</a>
</li>
<li>
<a href=https://tnwei.github.io/about/ title=About>
<span>About</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
MLflow x Hydra
</h1>
<div class=post-meta><span title="2022-06-13 20:58:18 +0800 +0800">Jun 13, 2022 Mon</span>&nbsp;·&nbsp;7 min
</div>
</header>
<div class=post-content><h2 id=a-template-for-using-both-effectively-in-machine-learning-experiments>A template for using both effectively in machine learning experiments<a hidden class=anchor aria-hidden=true href=#a-template-for-using-both-effectively-in-machine-learning-experiments>#</a></h2>
<p>I like using <a href=https://mlflow.org/>MLflow</a> for experiment tracking, and <a href=https://hydra.cc/>Hydra</a> for experiment configuration management and hyperparameter tuning. MLflow enables logging and visualizing all relevant info for each machine learning model trained without much effort. Hydra drastically simplifies managing and running experiments involving lots of hyperparameters, without requiring much extra code.</p>
<p>Although both libraries are functionally complementary, there are subtle interactions between them that can lead to unexpected gotchas that are barely mentioned on the internet. After a couple of projects, I eventually arrived at the annotated script template below for using MLflow and Hydra effectively in the same codebase.</p>
<p>If you&rsquo;re looking for a tweaked and tested template integrating both libraries to kick start your work, you might find this post useful.</p>
<h2 id=training-script-template>Training script template<a hidden class=anchor aria-hidden=true href=#training-script-template>#</a></h2>
<p>The sample config and training script template can be found at <a href=https://github.com/tnwei/mlflow-x-hydra>tnwei/mlflow-x-hydra</a>, reproduced below for copy-paste convenience.</p>
<h3 id=conftrainyaml><code>conf/train.yaml</code><a hidden class=anchor aria-hidden=true href=#conftrainyaml>#</a></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#75715e># Metadata</span>
<span style=color:#75715e># --------</span>
<span style=color:#f92672>expname</span>: <span style=color:#ae81ff>testrun</span>
<span style=color:#f92672>runname</span>: <span style=color:#75715e># Left blank on purpose, to be specified in CLI</span>

<span style=color:#75715e># Hyperparameters</span>
<span style=color:#75715e># ---------------</span>
<span style=color:#f92672>n_epochs</span>: <span style=color:#ae81ff>10</span>
<span style=color:#f92672>lr</span>: <span style=color:#ae81ff>1e-5</span>
<span style=color:#f92672>batch_size</span>: <span style=color:#ae81ff>32</span>

<span style=color:#75715e># Hydra-specific config</span>
<span style=color:#75715e># ---------------------</span>
<span style=color:#75715e># The following stores single runs and multiruns (sweeps) in a hidden .hydra dir</span>
<span style=color:#f92672>hydra</span>:
  <span style=color:#f92672>run</span>:
  <span style=color:#f92672>¦ dir</span>: <span style=color:#ae81ff>.hydra/${now:%Y-%m-%d_%H-%M-%S}</span>
  <span style=color:#ae81ff>¦</span> <span style=color:#75715e># If this works for you why not</span>
  <span style=color:#f92672>¦ # dir</span>: <span style=color:#ae81ff>.hydra/${expname}/${now:%Y-%m-%d_%H-%M-%S}</span>
  <span style=color:#f92672>sweep</span>:
  <span style=color:#f92672>¦ dir</span>: <span style=color:#ae81ff>.hydra/${now:%Y-%m-%d_%H-%M-%S}</span>
  <span style=color:#ae81ff>¦</span> <span style=color:#75715e># If this works for you why not</span>
  <span style=color:#f92672>¦ # dir</span>: <span style=color:#ae81ff>.hydra/${expname}/${now:%Y-%m-%d_%H-%M-%S}</span>
  <span style=color:#f92672>¦ subdir</span>: <span style=color:#ae81ff>${hydra.job.num}</span>
</code></pre></div><h3 id=mainpy><code>main.py</code><a hidden class=anchor aria-hidden=true href=#mainpy>#</a></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>Example multirun command: python main.py -m runname=testrun lr=1e-4,5e-5,1e-5,5e-6
</span><span style=color:#e6db74>&#34;&#34;&#34;</span>

<span style=color:#75715e># Import everything we need</span>
<span style=color:#75715e># -------------------------</span>
<span style=color:#f92672>import</span> sys
<span style=color:#f92672>from</span> pathlib <span style=color:#f92672>import</span> Path
<span style=color:#f92672>import</span> random
<span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt

<span style=color:#75715e># Import hydra and mlflow</span>
<span style=color:#75715e># -----------------------</span>
<span style=color:#f92672>import</span> hydra
<span style=color:#f92672>import</span> mlflow

<span style=color:#75715e># Obtain current working directory outside Hydra</span>
<span style=color:#75715e># ----------------------------------------------</span>
<span style=color:#75715e># Why: wd is changed temporarily for each Hydra run</span>
<span style=color:#75715e># Original wd can still be retrieved at runtime with</span>
<span style=color:#75715e># hydra.utils.get_original_cwd()</span>
<span style=color:#75715e># But I prefer sticking to std lib when possible</span>
wd <span style=color:#f92672>=</span> Path(__file__)<span style=color:#f92672>.</span>parent<span style=color:#f92672>.</span>resolve()

<span style=color:#75715e># Define MLflow tracking and artifact storage URI</span>
<span style=color:#75715e># -----------------------------------------------</span>
<span style=color:#75715e># This is required whenever a new MLflow experiment is defined</span>
<span style=color:#75715e># Do not change halfway through! Stick to one</span>
<span style=color:#75715e># Migrating mlflow backend is non-trivial</span>

<span style=color:#75715e># Default config: local backend + local artifact store</span>
<span style=color:#75715e># Command for UI: mlflow ui</span>
<span style=color:#75715e># Format for folder is `file://` + absolute file path, following file URI scheme</span>
TRACKING_URI <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;file://</span><span style=color:#e6db74>{</span>wd<span style=color:#e6db74>}</span><span style=color:#e6db74>/mlruns&#34;</span>  <span style=color:#75715e># This is default location</span>
ARTIFACT_URI <span style=color:#f92672>=</span> TRACKING_URI

<span style=color:#75715e># Alternative config: sqlite backend + local artifact store</span>
<span style=color:#75715e># Command for UI: mlflow ui --backend-store-uri sqlite:///mlruns.sqlite</span>
<span style=color:#75715e># Format for sqlite is `sqlite:///` + absolute file path. Three slashes!</span>
<span style=color:#75715e># TRACKING_URI = f&#34;sqlite:///{wd}/mlruns.sqlite&#34;</span>
<span style=color:#75715e># ARTIFACT_URI = f&#34;file://{wd}/mlruns&#34;</span>

<span style=color:#75715e># More options available but omitted for brevity</span>
<span style=color:#75715e># See https://www.mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded</span>

mlflow<span style=color:#f92672>.</span>set_tracking_uri(TRACKING_URI)

<span style=color:#75715e># Main logic</span>
<span style=color:#75715e># ----------</span>
<span style=color:#75715e># Main training logic needs to be:</span>
<span style=color:#75715e># (1) packaged into a function</span>
<span style=color:#75715e># (2) wrapped with hydra.main() decorator</span>
<span style=color:#75715e># (3) and called at the end of the script</span>
<span style=color:#75715e># for Hydra to work</span>
<span style=color:#75715e>#</span>
<span style=color:#75715e># Config path is dir to where the config is stored</span>
<span style=color:#75715e># Config name is the name of the config file</span>
<span style=color:#a6e22e>@hydra</span><span style=color:#f92672>.</span>main(config_path<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;conf&#34;</span>, config_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;train.yaml&#34;</span>)
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>(cfg):
    <span style=color:#75715e># Hydra config parsing</span>
    <span style=color:#75715e># --------------------</span>
    <span style=color:#75715e># cfg is literally a dict of everything defined in the conf file</span>
    <span style=color:#75715e># or passed from CLI</span>
    <span style=color:#75715e># refer to conf.yaml for example</span>
    print(cfg)

    <span style=color:#75715e># Unpack variables that will be used multiple times throughout the script</span>
    <span style=color:#75715e># -----------------------------------------------------------------------</span>
    <span style=color:#75715e># Why: This is to keep the script modular if migrating away from Hydra</span>
    <span style=color:#75715e># Saves time if want to switch to some other runner e.g. Weights and Biases sweeps</span>
    n_epochs <span style=color:#f92672>=</span> cfg<span style=color:#f92672>.</span>n_epochs
    lr <span style=color:#f92672>=</span> cfg<span style=color:#f92672>.</span>lr
    batch_size <span style=color:#f92672>=</span> cfg<span style=color:#f92672>.</span>batch_size

    <span style=color:#75715e># Set MLFlow experiment</span>
    <span style=color:#75715e># ---------------------</span>
    <span style=color:#75715e># All runs recorded under the same exp name will show up on the same table in MLFlow</span>
    <span style=color:#75715e># Create exp if not exists</span>
    <span style=color:#66d9ef>if</span> mlflow<span style=color:#f92672>.</span>get_experiment_by_name(cfg<span style=color:#f92672>.</span>expname) <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:
        mlflow<span style=color:#f92672>.</span>create_experiment(
            name<span style=color:#f92672>=</span>cfg<span style=color:#f92672>.</span>expname, artifact_location<span style=color:#f92672>=</span>ARTIFACT_URI <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;/&#34;</span> <span style=color:#f92672>+</span> cfg<span style=color:#f92672>.</span>expname
        )
    mlflow<span style=color:#f92672>.</span>set_experiment(cfg<span style=color:#f92672>.</span>expname)

    <span style=color:#75715e># Explicitly set new MLFlow run</span>
    <span style=color:#75715e># -----------------------------</span>
    <span style=color:#75715e># Explicitly set a new run:</span>
    <span style=color:#75715e># Why 1: Running w/ hydra will pick up from a prev run</span>
    <span style=color:#75715e># See https://stackoverflow.com/a/72605175/13095028</span>
    <span style=color:#75715e># Why 2: Allows fine-grained control over Run object e.g. setting `run_name`</span>
    <span style=color:#75715e># Note: Leaving run_id to be auto-generated, since the randomly generated UUID is convenient</span>
    activerun <span style=color:#f92672>=</span> mlflow<span style=color:#f92672>.</span>start_run(run_name<span style=color:#f92672>=</span>cfg<span style=color:#f92672>.</span>runname)

    <span style=color:#75715e># Explicitly configure savedir</span>
    <span style=color:#75715e># ----------------------------</span>
    <span style=color:#75715e># Why: Create consistent savedir for all MLflow exps instead of using Hydra</span>
    <span style=color:#75715e># Format: outputs/expname/runid/</span>
    <span style=color:#75715e># Hydra&#39;s approach will have one savedir for each run</span>
    <span style=color:#75715e># Use run ID instead of run name as latter isn&#39;t always defined</span>
    savedir <span style=color:#f92672>=</span> wd <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;outputs&#34;</span> <span style=color:#f92672>/</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>cfg<span style=color:#f92672>.</span>expname<span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>activerun<span style=color:#f92672>.</span>info<span style=color:#f92672>.</span>run_id<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
    <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> savedir<span style=color:#f92672>.</span>exists():
        savedir<span style=color:#f92672>.</span>mkdir(parents<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)

    <span style=color:#75715e># Log hyperparameters</span>
    <span style=color:#75715e># -------------------</span>
    <span style=color:#75715e># Params can only be logged once, while metrics are logged over time</span>

    <span style=color:#75715e># Log dict of parameters</span>
    mlflow<span style=color:#f92672>.</span>log_params(cfg)

    <span style=color:#75715e># Log one parameter</span>
    <span style=color:#75715e># Note: found logging the command that triggered the file to run to be useful</span>
    mlflow<span style=color:#f92672>.</span>log_param(<span style=color:#e6db74>&#34;argv&#34;</span>, <span style=color:#e6db74>&#34; &#34;</span><span style=color:#f92672>.</span>join(sys<span style=color:#f92672>.</span>argv))

    <span style=color:#75715e># Data loading and preprocessing</span>
    <span style=color:#75715e># ------------------------------</span>
    <span style=color:#75715e># ...</span>
    <span style=color:#75715e># YOUR CODE HERE</span>
    <span style=color:#75715e># ...</span>

    <span style=color:#75715e># Main training loop</span>
    <span style=color:#75715e># ------------------</span>

    <span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(n_epochs):
        <span style=color:#75715e># Model training</span>
        <span style=color:#75715e># --------------</span>
        <span style=color:#75715e># ...</span>
        <span style=color:#75715e># YOUR CODE HERE</span>
        <span style=color:#75715e># ...</span>

        <span style=color:#75715e># Compute evaluation metrics</span>
        <span style=color:#75715e># --------------------------</span>
        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Calculating metrics at step </span><span style=color:#e6db74>{</span>epoch<span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>n_epochs<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
        eval_metrics <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;acc&#34;</span>: epoch <span style=color:#f92672>/</span> n_epochs}

        <span style=color:#75715e># Log metrics</span>
        <span style=color:#75715e># -----------</span>
        <span style=color:#75715e># Log dict of metrics</span>
        mlflow<span style=color:#f92672>.</span>log_metrics(eval_metrics, step<span style=color:#f92672>=</span>epoch)

        <span style=color:#75715e># Log one metric</span>
        mlflow<span style=color:#f92672>.</span>log_metric(<span style=color:#e6db74>&#34;luck&#34;</span>, random<span style=color:#f92672>.</span>random(), step<span style=color:#f92672>=</span>epoch)

        <span style=color:#75715e># Save training outputs</span>
        <span style=color:#75715e># ---------------------</span>
        <span style=color:#75715e># Store artifacts by step in the defined savedir</span>
        (savedir <span style=color:#f92672>/</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>:</span><span style=color:#e6db74>02d</span><span style=color:#e6db74>}</span><span style=color:#e6db74>.csv&#34;</span>)<span style=color:#f92672>.</span>touch()

        <span style=color:#75715e># Create a plot</span>
        fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()
        ax<span style=color:#f92672>.</span>plot([<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>], [<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>])

        <span style=color:#75715e># If needed, log training outputs to MLflow artifact store</span>
        <span style=color:#75715e># --------------------------------------------------------</span>
        <span style=color:#75715e># Log one file</span>
        mlflow<span style=color:#f92672>.</span>log_artifact(local_path<span style=color:#f92672>=</span>savedir <span style=color:#f92672>/</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>:</span><span style=color:#e6db74>02d</span><span style=color:#e6db74>}</span><span style=color:#e6db74>.csv&#34;</span>)

        <span style=color:#75715e># Log the whole dir</span>
        mlflow<span style=color:#f92672>.</span>log_artifacts(local_dir<span style=color:#f92672>=</span>savedir)

        <span style=color:#75715e># Log a figure</span>
        mlflow<span style=color:#f92672>.</span>log_figure(fig, artifact_file<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>:</span><span style=color:#e6db74>02d</span><span style=color:#e6db74>}</span><span style=color:#e6db74>.png&#34;</span>)

    <span style=color:#75715e># End MLflow run</span>
    <span style=color:#75715e># --------------</span>
    <span style=color:#75715e># Alternative: wrap code in `with mlflow.start_run() as run:`</span>
    mlflow<span style=color:#f92672>.</span>end_run()


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
    main()
</code></pre></div><h2 id=reasoning>Reasoning<a hidden class=anchor aria-hidden=true href=#reasoning>#</a></h2>
<p>Elaborating upon the more opinionated parts of the template below:</p>
<h3 id=obtain-current-working-directory-outside-hydra>Obtain current working directory outside Hydra<a hidden class=anchor aria-hidden=true href=#obtain-current-working-directory-outside-hydra>#</a></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># main.py</span>
wd <span style=color:#f92672>=</span> Path(__file__)<span style=color:#f92672>.</span>parent<span style=color:#f92672>.</span>resolve()
</code></pre></div><p>Hydra changes the work directory temporarily every time the script is executed. The idea is each script execution will have its outputs saved to a standalone folder. To refer to files based on the original working directory, we can either call <code>hydra.utils.get_original_cwd()</code>, or as I prefer it, save the original working directory using <code>pathlib</code> which is a standard library in Python.</p>
<h3 id=unpack-variables-that-will-be-used-multiple-times-throughout-the-script>Unpack variables that will be used multiple times throughout the script<a hidden class=anchor aria-hidden=true href=#unpack-variables-that-will-be-used-multiple-times-throughout-the-script>#</a></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># main.py</span>
n_epochs <span style=color:#f92672>=</span> cfg<span style=color:#f92672>.</span>n_epochs
lr <span style=color:#f92672>=</span> cfg<span style=color:#f92672>.</span>lr
batch_size <span style=color:#f92672>=</span> cfg<span style=color:#f92672>.</span>batch_size
</code></pre></div><p>All specified configs will be made available through the <code>cfg</code> argument passed to the <code>main()</code> function, as items in a dictionary. Instead of directly referring to these values, I assign them to independent variables at the start of the script. I prefer keeping the Hydra-specific code localized to just the head of the script. In the event that I want to use another script runner like Weights and Biases sweeps instead, refactoring will just need tweaking a few lines.</p>
<h3 id=explicitly-set-new-mlflow-run>Explicitly set new MLFlow run<a hidden class=anchor aria-hidden=true href=#explicitly-set-new-mlflow-run>#</a></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># main.py</span>
activerun <span style=color:#f92672>=</span> mlflow<span style=color:#f92672>.</span>start_run(run_name<span style=color:#f92672>=</span>cfg<span style=color:#f92672>.</span>runname)
</code></pre></div><p>An MLflow Run is created explicitly in the script template. The reasons are two-fold:</p>
<ol>
<li>If left to be automatically managed by MLflow, Hydra will consider all MLflow runs in the same Hydra multirun session to be the same. See <a href=https://stackoverflow.com/a/72605175/13095028>my answer to this Stackoverflow question</a></li>
<li>Explicit run creation allows greater control over the MLflow Run object. Example here is it allows us to set the <code>run_name</code>, which would be blank in the MLflow UI otherwise.</li>
</ol>
<h3 id=explicitly-configure-savedir>Explicitly configure savedir<a hidden class=anchor aria-hidden=true href=#explicitly-configure-savedir>#</a></h3>
<p>Out of the box, Hydra creates an <code>outputs/</code>directory to store the results of each execution, sorted by date. Results for each execution is saved in its own folder, using the current timestamp to the second as the folder name. Multiruns are stored in a separate <code>multirun</code> folder. This behaviour is convenient for integrating Hydra within existing code without much modification, but can be a bit tedious when it comes to accessing past results for future use.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># main.py</span>
savedir <span style=color:#f92672>=</span> wd <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;outputs&#34;</span> <span style=color:#f92672>/</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>cfg<span style=color:#f92672>.</span>expname<span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>activerun<span style=color:#f92672>.</span>info<span style=color:#f92672>.</span>run_id<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
<span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> savedir<span style=color:#f92672>.</span>exists():
    savedir<span style=color:#f92672>.</span>mkdir(parents<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#75715e># conf/train.yaml</span>
<span style=color:#f92672>hydra</span>:
  <span style=color:#f92672>run</span>:
    <span style=color:#f92672>dir</span>: <span style=color:#ae81ff>.hydra/${now:%Y-%m-%d_%H-%M-%S}</span>
  <span style=color:#f92672>sweep</span>:
    <span style=color:#f92672>dir</span>: <span style=color:#ae81ff>.hydra/${now:%Y-%m-%d_%H-%M-%S}</span>
    <span style=color:#f92672>subdir</span>: <span style=color:#ae81ff>${hydra.job.num}</span>
</code></pre></div><p>In this script template, the output directory is explicitly configured to be <code>&lt;cwd> /outputs/</code>, further sorted by experiment name and MLflow run ID. This approach consolidates all output into a single folder, compared to Hydra&rsquo;s default approach. Given that Hydra still creates output directories for each execution, the template redirects them to a <code>.hydra</code> directory which is out of sight.</p>
<p>I would have preferred using Hydra&rsquo;s configuration to determine the save location instead of setting it aside completely, but the save locations are determined upon execution, and Hydra does not accept variables created at runtime. Using the Hydra config would rule out using auto-generated names, requiring the user to manually provide a name for each script execution.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://tnwei.github.io/tags/mlops/>mlops</a></li>
</ul>
</footer><script src=https://giscus.app/client.js data-repo=tnwei/tnwei.github.io data-repo-id=R_kgDOGmOfvQ data-category=Announcements data-category-id=DIC_kwDOGmOfvc4CAeit data-mapping=og:title data-reactions-enabled=0 data-emit-metadata=0 data-theme=light data-lang=en crossorigin=anonymous async></script>
<noscript></noscript>
</article>
</main>
<footer class=footer>
<span>&copy; 2024 <a href=https://tnwei.github.io/>Tan Nian Wei</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
</body>
</html>